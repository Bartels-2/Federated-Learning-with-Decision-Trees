{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import psutil\n",
    "import time\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from lightgbm.sklearn import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdaten: (30162, 104) (30162,)\n",
      "Testdaten: (15059, 104) (15059,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "columns = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "# loads and preprocesses the data\n",
    "def preprocess_data(file_path, is_test=False):\n",
    "    # Laden der Daten\n",
    "    data = pd.read_csv(file_path, header=None, names=columns, sep=\",\\s*\", engine='python', skiprows=1 if is_test else 0)\n",
    "\n",
    "    # discards elements with missing values\n",
    "    data.replace(\"?\", np.nan, inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # removes a . in the target variable\n",
    "    if is_test:\n",
    "        data['income'] = data['income'].str.rstrip('.')\n",
    "\n",
    "    # one hot encoding\n",
    "    data = pd.get_dummies(data, columns=[\n",
    "        \"workclass\", \"education\", \"marital-status\", \"occupation\",\n",
    "        \"relationship\", \"race\", \"sex\", \"native-country\"\n",
    "    ])\n",
    "\n",
    "    # binary encoding for the target class\n",
    "    data['income'] = data['income'].apply(lambda x: 1 if x == \">50K\" else 0)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "train_file = \"data/adult/adult.data\"\n",
    "test_file = \"data/adult/adult.test\"\n",
    "\n",
    "train_data = preprocess_data(train_file, is_test=False)\n",
    "test_data = preprocess_data(test_file, is_test=True)\n",
    "\n",
    "\n",
    "missing_cols = set(train_data.columns) - set(test_data.columns)\n",
    "for col in missing_cols:\n",
    "    test_data[col] = 0\n",
    "\n",
    "test_data = test_data[train_data.columns]\n",
    "\n",
    "# normalizes numerical data\n",
    "scaler = MinMaxScaler()\n",
    "numerical_columns = [\"age\", \"fnlwgt\", \"education-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "\n",
    "# skales the data\n",
    "train_data[numerical_columns] = scaler.fit_transform(train_data[numerical_columns])\n",
    "test_data[numerical_columns] = scaler.transform(test_data[numerical_columns])\n",
    "\n",
    "\n",
    "X_train = train_data.drop(\"income\", axis=1).to_numpy().astype(np.float32)\n",
    "y_train = train_data[\"income\"].to_numpy().astype(np.float32)\n",
    "\n",
    "X_test = test_data.drop(\"income\", axis=1).to_numpy().astype(np.float32)\n",
    "y_test = test_data[\"income\"].to_numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "print(\"Trainingsdata:\", X_train.shape, y_train.shape)\n",
    "print(\"Testdata:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to get the paths within a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_tree_with_classes(tree, node_id=0, path=None):\n",
    "    \"\"\"\n",
    "    Recursive function that traverses all paths from the root to the leafs in order to return the possible pathes and the class information of each leaf\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        path = []\n",
    "\n",
    "    # checks if the current node is a leaf\n",
    "    if tree.children_left[node_id] == -1 and tree.children_right[node_id] == -1:\n",
    "\n",
    "        class_distribution = tree.value[node_id][0]\n",
    "        majority_class = class_distribution.argmax()\n",
    "        return [(path, len(path), majority_class)]\n",
    "\n",
    "    # contains all paths\n",
    "    paths = []\n",
    "\n",
    "\n",
    "    left_child = tree.children_left[node_id]\n",
    "    if left_child != -1:\n",
    "        condition = (tree.feature[node_id], \"<=\", tree.threshold[node_id])\n",
    "        paths += traverse_tree_with_classes(tree, left_child, path + [condition])\n",
    "\n",
    "\n",
    "    right_child = tree.children_right[node_id]\n",
    "    if right_child != -1:\n",
    "        condition = (tree.feature[node_id], \">\", tree.threshold[node_id])\n",
    "        paths += traverse_tree_with_classes(tree, right_child, path + [condition])\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the decision tree client models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from sys import getsizeof\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "num_trees = 200\n",
    "average_train_score = 0\n",
    "average_test_score_tree = 0\n",
    "lowest_test_score = 1\n",
    "\n",
    "\n",
    "X_splits = np.array_split(X_train, num_trees)\n",
    "y_splits = np.array_split(y_train, num_trees)\n",
    "\n",
    "\n",
    "trees = []\n",
    "tree_sizes = []\n",
    "computation_times = []\n",
    "\n",
    "\n",
    "individual_metrics = []\n",
    "\n",
    "for i in range(num_trees):\n",
    "    start_time = time.time()\n",
    "\n",
    "    tree = DecisionTreeClassifier(\n",
    "        criterion=\"entropy\",\n",
    "        splitter=\"best\",\n",
    "        max_depth=3,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        max_features=None,\n",
    "        class_weight=\"balanced\",\n",
    "    )\n",
    "    tree.fit(X_splits[i], y_splits[i])\n",
    "    end_time = time.time()\n",
    "\n",
    " \n",
    "    trees.append(tree)\n",
    "\n",
    "    \n",
    "    computation_time = end_time - start_time\n",
    "    computation_times.append(computation_time)\n",
    "\n",
    "    tree_size = getsizeof(tree)\n",
    "    tree_sizes.append(tree_size)\n",
    "\n",
    "    \n",
    "    test_acc = accuracy_score(y_test, tree.predict(X_test))\n",
    "    train_acc = accuracy_score(y_splits[i], tree.predict(X_splits[i]))\n",
    "\n",
    "    average_test_score_tree += test_acc\n",
    "    average_train_score += train_acc\n",
    "\n",
    "    if test_acc < lowest_test_score:\n",
    "        lowest_test_score = test_acc\n",
    "\n",
    "    \n",
    "    individual_metrics.append({\n",
    "        \"Tree\": i + 1,\n",
    "        \"Size (bytes)\": tree_size,\n",
    "        \"Computation Time (seconds)\": round(computation_time, 4),\n",
    "        \"Train Accuracy\": round(train_acc, 4),\n",
    "        \"Test Accuracy\": round(test_acc, 4),\n",
    "    })\n",
    "\n",
    "\n",
    "average_tree_size = sum(tree_sizes) / len(tree_sizes)\n",
    "average_computation_time = sum(computation_times) / len(computation_times)\n",
    "\n",
    "\n",
    "aktuelles_datum = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "output_file = \"tree_metrics_bank.xlsx\"\n",
    "\n",
    "\n",
    "individual_metrics_df = pd.DataFrame(individual_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_final = []\n",
    "y_combined_final = []\n",
    "y_flipped_combined_final =[] \n",
    "\n",
    "\n",
    "for i in range(num_trees):\n",
    "    tree = trees[i].tree_\n",
    "\n",
    "# traverses all trees from the root to the leafs\n",
    "    paths_with_classes = traverse_tree_with_classes(tree)\n",
    "    n_samples =100\n",
    "    n_features = 104\n",
    "    alpha = 0.1\n",
    "\n",
    "    first_data = 1\n",
    "\n",
    "    X_combined_list = []\n",
    "    y_combined_list = []\n",
    "    y_flipped_list = []\n",
    "\n",
    "    for (path,length, class_of_node) in paths_with_classes:\n",
    "        #print(\"Zugriff auf den ersten Pfad der länge\", length)\n",
    "        for i in range(1, length + 1):\n",
    "            #print(f\"    Zugriff auf die letzten {i} Bedingungen:\")\n",
    "            first_run = 1\n",
    "            for condition in path[-i:]:\n",
    "                feature, operator, threshold = condition\n",
    "                #print(f\"        Feature {feature} {operator} {threshold}\")\n",
    "                #print(\"         Klasse\", class_of_node)\n",
    "                feature_index = feature\n",
    "\n",
    "                if(operator == \"<=\"):\n",
    "                    #print('         Kleinere Auswertung')\n",
    "                    split_feature_values = np.random.uniform(\n",
    "                    threshold - alpha * threshold,  # lower bound\n",
    "                    threshold,  # upper bound\n",
    "                    n_samples                     # number of samples\n",
    "                    )\n",
    "\n",
    "                if(operator == \">\"):\n",
    "                    #print(\"         Größere Auswertung\")\n",
    "                    split_feature_values = np.random.uniform(\n",
    "                    threshold,  # lower bound \n",
    "                    threshold + alpha * threshold,  # upper bound\n",
    "                    n_samples                     # number of samples\n",
    "                    )\n",
    "\n",
    "                if(first_run == 1):\n",
    "                    #print(\"Erster Run deshalb X_syn random initialisiert\")\n",
    "                    X_syn = np.random.choice([-100000, 500000], size=(n_samples, n_features)) \n",
    "                    y_syn = np.where(X_syn[:, feature_index] <= threshold, class_of_node, 1-class_of_node)\n",
    "                    y_flipped = np.zeros(n_samples) \n",
    "                    first_run = 0\n",
    "\n",
    "                X_syn[:, feature_index] = split_feature_values\n",
    "\n",
    "            if(i < length):\n",
    "                #print(\"Entropy hinzugefügt, da Pfad nicht komplett\")\n",
    "                #print(i/length)\n",
    "                random_flip = np.random.rand(len(y_syn))\n",
    "                #flip_indices = random_flip > i/length\n",
    "                if(i == length-1):\n",
    "                    flip_indices = random_flip < 0.55\n",
    "                if(i == length-2):\n",
    "                    flip_indices = random_flip < 0.65\n",
    "                if(i == length-3):\n",
    "                    flip_indices = random_flip < 0.85\n",
    "                y_syn[flip_indices] = 1 - y_syn[flip_indices]\n",
    "                y_flipped[flip_indices] = 1\n",
    "            #print()\n",
    "            if(first_data == 1):\n",
    "                X_combined = X_syn\n",
    "                y_combined = y_syn\n",
    "                first_data = 0\n",
    "            #print(X_syn[0])\n",
    "            #print(y_syn[0])\n",
    "            X_combined_list.append(X_syn)\n",
    "            y_combined_list.append(y_syn)\n",
    "            y_flipped_list.append(y_flipped) \n",
    "\n",
    "\n",
    "    X_combined = np.vstack(X_combined_list)\n",
    "    print(\"X_combined\",X_combined.shape)\n",
    "    y_combined = np.hstack(y_combined_list)\n",
    "    y_flipped_combined = np.hstack(y_flipped_list) \n",
    "    print(y_combined.shape)\n",
    "    print(y_flipped_combined.shape) \n",
    "    X_combined_final.append(X_combined)\n",
    "    y_combined_final.append(y_combined)\n",
    "    y_flipped_combined_final.append(y_flipped_combined)\n",
    "\n",
    "X_combined_final = np.vstack(X_combined_final)\n",
    "y_combined_final = np.hstack(y_combined_final)\n",
    "y_flipped_combined_final = np.hstack(y_flipped_combined_final)\n",
    "print(y_combined_final.shape)\n",
    "print(y_flipped_combined_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority vote for the class of the synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374200,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "predictions = np.array([tree.predict(X_combined_final) for tree in trees])\n",
    "\n",
    "\n",
    "y_combined_final, _ = mode(predictions, axis=0)\n",
    "y_combined_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition of entropy in order to get more stable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Häufigkeiten in flipped: [230445 143755]\n",
      "Häufigkeiten in y: [308760  65440]\n",
      "Häufigkeiten in y nach flip: [235611 138589]\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(y_flipped_combined_final, return_counts=True)\n",
    "print(\"Häufigkeiten in flipped:\", counts)\n",
    "\n",
    "unique_values, counts = np.unique(y_combined_final, return_counts=True)\n",
    "print(\"Häufigkeiten in y:\", counts)\n",
    "y_flipped_combined_final = y_flipped_combined_final.astype(int)\n",
    "y_combined_final = y_combined_final.astype(int)\n",
    "\n",
    "y_combined_final = y_flipped_combined_final ^ y_combined_final\n",
    "\n",
    "unique_values, counts = np.unique(y_combined_final, return_counts=True)\n",
    "print(\"Häufigkeiten in y nach flip:\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the global Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy auf Trainingsdaten: 0.65\n",
      "Accuracy auf Testdaten: 0.75\n",
      "Metrics saved to tree_metrics_bank.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thilo\\Desktop\\Federated_Learning\\Federated-Learning\\.venv\\Lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "clf_syn = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    splitter=\"best\",\n",
    "    max_depth=7,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=None, # none lässt alle features zum erstellen zu\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "\n",
    "clf_syn.fit(X_combined_final, y_combined_final)\n",
    "\n",
    "y_syn_train_pred = clf_syn.predict(X_combined_final)\n",
    "y_syn_test_pred = clf_syn.predict(X_test)\n",
    "\n",
    "\n",
    "train_accuracy_syn = accuracy_score(y_combined_final, y_syn_train_pred)\n",
    "average_test_score_tree_main = accuracy_score(y_test, y_syn_test_pred)\n",
    "\n",
    "print(f\"Accuracy auf Trainingsdaten: {train_accuracy_syn:.2f}\")\n",
    "print(f\"Accuracy auf Testdaten: {average_test_score_tree_main:.2f}\")\n",
    "\n",
    "feature_names = [\n",
    "    \"Feature1\", \"Feature2\", \"Feature3\", \"Feature4\",\n",
    "    \"Feature5\", \"Feature6\", \"Feature7\", \"Feature8\",\n",
    "    \"Feature9\", \"Feature10\", \"Feature11\", \"Feature12\",\n",
    "    \"Feature13\", \"Feature14\", \"Feature15\", \"Feature16\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "summary_data = {\n",
    "    \"Metric\": [\n",
    "        \"Number of Trees\",\n",
    "        \"Train Score on synthetic data\",\n",
    "        \"Final Test Score\",\n",
    "        \"Average Tree Size (bytes)\",\n",
    "        \"Average Computation Time (seconds)\",\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        num_trees,\n",
    "        round(train_accuracy_syn, 4),\n",
    "        round(average_test_score_tree_main, 4),\n",
    "        round(average_tree_size, 4),\n",
    "        round(average_computation_time, 4),\n",
    "    ],\n",
    "}\n",
    "summary_df = pd.DataFrame(summary_data).set_index(\"Metric\").transpose()\n",
    "\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    \n",
    "    print(\"exists\")\n",
    "    with pd.ExcelWriter(output_file, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "        summary_df.to_excel(writer, sheet_name=f\"{aktuelles_datum}_Summary\", index=False)\n",
    "        individual_metrics_df.to_excel(writer, sheet_name=f\"{aktuelles_datum}_Individual Metrics\", index=False)\n",
    "else:\n",
    "    \n",
    "    with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
    "        summary_df.to_excel(writer, sheet_name=f\"{aktuelles_datum}_Summary\", index=False)\n",
    "        individual_metrics_df.to_excel(writer, sheet_name=f\"{aktuelles_datum}_Individual Metrics\", index=False)\n",
    "\n",
    "print(f\"Metrics saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the Fed-AVG algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7542997542997543\n",
      "Round 1/70\n",
      "  Global Model on Test Data: Accuracy = 0.75\n",
      "  Average Client Accuracy on Training Data: 0.55\n",
      "  Average Client Accuracy on Test Data: 0.54\n",
      "treshold: 0.7542997542997543\n",
      "\n",
      "Stopping training as global test accuracy reached 0.54 (>= 0.7542997542997543).\n",
      "Final Global Model Evaluation\n",
      "Final Global Model Accuracy on Training Data = 0.75\n",
      "Final Global Model Accuracy on Test Data = 0.75\n",
      "Average Computation Time per Round: 0.0094 seconds\n",
      "Average Weight Size: 528.00 bytes\n",
      "Average Time per Epoch: 0.0009 seconds\n",
      "Aktuelles Datum und Uhrzeit: 2025-01-28_21-05-10\n",
      "Metrics saved to nn_metrics_federated.xlsx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sys import getsizeof\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Neural Network Definition\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.output = nn.Linear(hidden_sizes[1], output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden1(x))\n",
    "        x = self.activation(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Federated Averaging\n",
    "def federated_averaging(models):\n",
    "    global_model = models[0]\n",
    "    global_dict = global_model.state_dict()\n",
    "\n",
    "    for key in global_dict.keys():\n",
    "        global_dict[key] = torch.mean(torch.stack([model.state_dict()[key].float() for model in models]), dim=0)\n",
    "\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    return global_model\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X, dtype=torch.float32))\n",
    "        predictions = torch.argmax(outputs, dim=1).numpy()\n",
    "        accuracy = accuracy_score(y, predictions)\n",
    "    return accuracy\n",
    "print(average_test_score_tree_main)\n",
    "# Data and Parameters\n",
    "num_clients = len(X_splits)\n",
    "input_size = X_splits[0].shape[1]\n",
    "hidden_sizes = [12, 12]\n",
    "output_size = len(np.unique(y_train))  # Number of classes\n",
    "epochs = 10\n",
    "rounds = 70\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "stop_threshold = average_test_score_tree_main  # Stop if test accuracy reaches this value\n",
    "\n",
    "avg_acc_client = 0\n",
    "avg_acc_client_test = 0\n",
    "# Initialize Models for Each Client\n",
    "client_models = [SimpleNN(input_size, hidden_sizes, output_size) for _ in range(num_clients)]\n",
    "client_optimizers = [optim.Adam(model.parameters(), lr=learning_rate) for model in client_models]\n",
    "\n",
    "# Global Model\n",
    "global_model = SimpleNN(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Metrics Storage\n",
    "total_computation_time = 0\n",
    "round_computation_times = []\n",
    "weight_sizes = []\n",
    "client_computation_times = []\n",
    "client_weight_sizes = []\n",
    "epoch_times = []\n",
    "average_train_accuracies = []\n",
    "average_test_accuracies = []\n",
    "\n",
    "# Federated Learning Rounds\n",
    "for round_idx in range(rounds):\n",
    "    print(f\"Round {round_idx + 1}/{rounds}\")\n",
    "\n",
    "    # Distribute Global Model to Clients\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "    # Training\n",
    "    round_start_time = time.time()\n",
    "    round_client_times = []\n",
    "    round_client_weights = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        # Train each client\n",
    "        for client_idx, (model, optimizer, X_client, y_client) in enumerate(zip(client_models, client_optimizers, X_splits, y_splits)):\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            X_client_tensor = torch.tensor(X_client, dtype=torch.float32)\n",
    "            y_client_tensor = torch.tensor(y_client, dtype=torch.long)\n",
    "\n",
    "            outputs = model(X_client_tensor)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, y_client_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Measure computation time\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            epoch_times.append(epoch_time)\n",
    "            total_computation_time += epoch_time\n",
    "            \n",
    "            round_client_times.append(epoch_time)\n",
    "\n",
    "            # Evaluate local model\n",
    "            acc_client = evaluate_model(model, X_client, y_client)\n",
    "            avg_acc_client += acc_client\n",
    "\n",
    "            acc_test = evaluate_model(model, X_test, y_test)\n",
    "            avg_acc_client_test += acc_test\n",
    "\n",
    "            # Measure client weight size\n",
    "            client_weight_size = sum(getsizeof(param) for param in model.state_dict().values())\n",
    "            round_client_weights.append(client_weight_size)\n",
    "\n",
    "    \n",
    "\n",
    "    # Round Metrics\n",
    "    round_time = time.time() - round_start_time\n",
    "    round_computation_times.append(round_time)\n",
    "    #total_computation_time += round_time\n",
    "\n",
    "    # Federated Averaging\n",
    "    global_model = federated_averaging(client_models)\n",
    "\n",
    "    # Measure global weight size\n",
    "    global_weights_size = sum(getsizeof(param) for param in global_model.state_dict().values())\n",
    "    weight_sizes.append(global_weights_size)\n",
    "\n",
    "    # Store client metrics for this round\n",
    "    client_computation_times.append(round_client_times)\n",
    "    client_weight_sizes.append(round_client_weights)\n",
    "\n",
    "    # Calculate and store average accuracies\n",
    "    avg_train_accuracy = (avg_acc_client / num_clients) / epochs\n",
    "    avg_test_accuracy = (avg_acc_client_test / num_clients) / epochs\n",
    "    average_train_accuracies.append(avg_train_accuracy)\n",
    "    average_test_accuracies.append(avg_test_accuracy)\n",
    "\n",
    "    # Evaluate Global Model\n",
    "    global_accuracy = evaluate_model(global_model, X_test, y_test)\n",
    "    print(f\"  Global Model on Test Data: Accuracy = {global_accuracy:.2f}\")\n",
    "    print(f\"  Average Client Accuracy on Training Data: {avg_train_accuracy:.2f}\")\n",
    "    print(f\"  Average Client Accuracy on Test Data: {avg_test_accuracy:.2f}\")\n",
    "    print(f\"treshold: {stop_threshold}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Reset average values\n",
    "    avg_acc_client = 0\n",
    "    avg_acc_client_test = 0\n",
    "\n",
    "    # Stop training if test accuracy threshold is met\n",
    "    if global_accuracy >= stop_threshold:\n",
    "        print(f\"Stopping training as global test accuracy reached {avg_test_accuracy:.2f} (>= {stop_threshold}).\")\n",
    "        break\n",
    "\n",
    "# Final Evaluation\n",
    "print(\"Final Global Model Evaluation\")\n",
    "final_accuracy = evaluate_model(global_model, np.vstack(X_splits), np.concatenate(y_splits))\n",
    "print(f\"Final Global Model Accuracy on Training Data = {final_accuracy:.2f}\")\n",
    "final_accuracy = evaluate_model(global_model, X_test, y_test)\n",
    "print(f\"Final Global Model Accuracy on Test Data = {final_accuracy:.2f}\")\n",
    "\n",
    "# Print Metrics\n",
    "average_computation_time = total_computation_time / ((round_idx + 1) * 200)\n",
    "average_weight_size = sum(weight_sizes) / len(weight_sizes)\n",
    "average_epoch_time = sum(epoch_times) / len(epoch_times)\n",
    "\n",
    "print(f\"Average Computation Time per Round: {average_computation_time:.4f} seconds\")\n",
    "print(f\"Average Weight Size: {average_weight_size:.2f} bytes\")\n",
    "print(f\"Average Time per Epoch: {average_epoch_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "aktuelles_datum = datetime.now()\n",
    "aktuelles_datum = aktuelles_datum.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "print(\"Aktuelles Datum und Uhrzeit:\", aktuelles_datum)\n",
    "\n",
    "\n",
    "output_file = \"nn_metrics_federated.xlsx\"\n",
    "\n",
    "\n",
    "summary_data = {\n",
    "    \"Metric\": [\n",
    "        \"Number of Rounds\",\n",
    "        \"Total Computation Time (seconds)\",\n",
    "        \"Average Computation Time per Round (seconds)\",\n",
    "        \"Average Weight Size (bytes)\",\n",
    "        \"Average Time per Epoch (seconds)\",\n",
    "        \"Final Test Accuracy\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        round_idx + 1,\n",
    "        total_computation_time,\n",
    "        average_computation_time,\n",
    "        average_weight_size,\n",
    "        average_epoch_time,\n",
    "        final_accuracy,\n",
    "    ],\n",
    "}\n",
    "summary_df = pd.DataFrame(summary_data).set_index(\"Metric\").transpose()\n",
    "\n",
    "\n",
    "round_data = {\n",
    "    \"Round\": list(range(1, round_idx + 2)),\n",
    "    \"Round Computation Time (seconds)\": round_computation_times,\n",
    "    \"Global Weight Size (bytes)\": weight_sizes,\n",
    "}\n",
    "round_df = pd.DataFrame(round_data)\n",
    "\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "\n",
    "    with pd.ExcelWriter(output_file, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "        summary_df.to_excel(writer, sheet_name=f\"{aktuelles_datum}_Summary\", index=False)\n",
    "        round_df.to_excel(writer, sheet_name=f\"{aktuelles_datum}_Rounds\", index=False)\n",
    "else:\n",
    "\n",
    "    with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
    "        summary_df.to_excel(writer, sheet_name=f\"{aktuelles_datum}_Summary\", index=False)\n",
    "        round_df.to_excel(writer, sheet_name=f\"{aktuelles_datum}_Rounds\", index=False)\n",
    "\n",
    "print(f\"Metrics saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
